# Wiki-Chatbot
Creaci贸n de un chatbot en Streamlit utilizando el framework Langchain y el dataset de Wikimedia.

#  Dataset utilizado
Se utiliz贸 el dataset de Wikimedia en espa帽ol, espec铆ficamente la versi贸n [20231101](https://huggingface.co/datasets/wikimedia/wikipedia/viewer/20231101.es). Para ejecutar el c贸digo que genera la base de datos vectorial, es necesario que estos archivos est茅n en el mismo directorio que el c贸digo.

#  Ejecuci贸n del archivo carga_datos.ipynb
En este archivo se encuentra el procedimiento utilizado para generar los datos en la base de datos vectorial FAISS. Si se desea descargar directamente el archivo FAISS, se encuentra en este [enlace](https://drive.google.com/file/d/1DEGFLW81RfkzR_Uiizu5hxaSj0CCDpKD/view?usp=sharing), el cual es necesario descomprimit.

## TextSplitter
Para la segmentaci贸n del texto, se utiliz贸 RecursiveCharacterTextSplitter de LangChain, ya que permite dividir documentos largos en fragmentos m谩s peque帽os, manteniendo la coherencia del contenido.

## Embedding
Para la conversi贸n de texto a vectores se utiliz贸 el modelo sentence-transformers de Hugging Face. Esto permite representar documentos y consultas en un espacio vectorial, facilitando la b煤squeda de informaci贸n relevante. Una de las principales razones para utilizar este embedding es su uso gratuito.

## Generaci贸n del faiss.index
Debido a la cantidad de datos, en esta ocasi贸n no fue posible guardar todos los datos del dataset en el archivo de FAISS. Se utiliz贸 un m茅todo de carga por lotes para realizar los embeddings y guardarlos en la base de datos vectorial.

#  Ejecuci贸n del chatbot
Para la ejecuci贸n del chatbot, es necesario ejecutar ` streamlit run chatbot.py ` y tener configurada la GOOGLE_API_KEY y la ruta del archivo faiss.index en las variables de entorno (archivo .env)

## Cadena utilizada
Los pasos para generar una respuesta son los siguientes:

1. Se define el modelo de embedding utilizado
2. Se carga el archivo faiss.index
3. Se carga el modelo de lenguaje a utilizar, en este caso, gemini-2.0 utilizando la API
4. Se crea el retriever a partir del archivo de base de datos vectorial
5. Se crea el prompt para contextualizar las preguntas. Esto es 煤til si la pregunta del usuario es ambigua y depende del contexto previo.
6. Se crea un retriever mejorado con contexto, que reformula la pregunta usando el historial antes de buscar en FAISS.
7. Se define el prompt principal que el LLM usar谩 para generar respuestas.
8. Se crea una cadena que toma el contexto recuperado y lo pasa al LLM junto con la pregunta del usuario.
9. Se combina el retriever mejorado y la cadena de generaci贸n de respuestas en una sola estructura.
10. A partir del prompt y el historial de mensajes, se llama a esta cadena final con el m茅todo ` invoke `

#  Funcionalidades
1. El chatbot tiene un historial de conversaci贸n utilizando el m茅todo que se menciono antes.
2. Se pueden tener varios chats.

#  Ejemplos

## Contexto de la conversaci贸n

![Wiki Chatbot recuerda el nombre](/memoria.jpeg)

## Ejemplo de preguntas que se pueden hacer al chatbot
![Pregunta sobre agujeros negros](/pregunta1.jpeg)

![Pregunta sobre Pablo Neruda](/pregunta2.jpeg)
   


